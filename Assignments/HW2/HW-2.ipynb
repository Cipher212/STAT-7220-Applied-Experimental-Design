{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Homework Repo Setup\n",
        "\n",
        "# 1. ENTER your GitHub username (the one that owns your fork)\n",
        "github_username =\"Cipher212\"\n",
        "\n",
        "# 2. Name of the repo (don't change unless your fork name is different)\n",
        "repo_name = \"STAT-7220-Applied-Experimental-Design\"\n",
        "\n",
        "# 3. Build the full repo URL for cloning\n",
        "repo_url = f\"https://github.com/{github_username}/{repo_name}.git\"\n",
        "\n",
        "import os\n",
        "\n",
        "# --- Ensure we start from /content ---\n",
        "# This is crucial to prevent nested cloning/directory changes if notebook was previously run\n",
        "initial_cwd = os.getcwd()\n",
        "if initial_cwd != \"/content\":\n",
        "    os.chdir(\"/content\")\n",
        "    print(f\"ðŸŒ Changed to /content from {initial_cwd}\")\n",
        "else:\n",
        "    print(f\"ðŸŒ Already in /content.\")\n",
        "\n",
        "\n",
        "# --- Handle repo cloning and initial directory change ---\n",
        "if os.path.exists(repo_name) and os.path.isdir(repo_name):\n",
        "    # If repo exists, simply change into it from /content\n",
        "    os.chdir(repo_name)\n",
        "    print(f\"âœ… Repo '{repo_name}' already exists. Changed directory to: {os.getcwd()}\")\n",
        "else:\n",
        "    # If repo does not exist, clone it\n",
        "    print(f\"ðŸ“¥ Cloning repo from {repo_url}...\")\n",
        "    os.system(f\"git clone {repo_url}\")\n",
        "    # After cloning, change into the newly created repo directory (which is now in /content)\n",
        "    if os.path.exists(repo_name):\n",
        "        os.chdir(repo_name)\n",
        "        print(f\"ðŸ“‚ Changed directory to: {os.getcwd()}\")\n",
        "    else:\n",
        "        print(\"âŒ ERROR: Repo folder not found after cloning. Please check your GitHub username.\")\n",
        "\n",
        "# --- Check if this is the instructor's repo instead of student's fork ---\n",
        "remote_url = os.popen(\"git config --get remote.origin.url\").read().strip()\n",
        "\n",
        "if \"abrown9008\" in remote_url:\n",
        "    print(\"âš ï¸ WARNING: You are working in the instructor's repo, not your fork!\")\n",
        "    print(\"ðŸ’¡ Please fork the repo to your own account and update `github_username` above.\")\n",
        "else:\n",
        "    print(f\"ðŸ”— Connected to fork at: {remote_url}\")\n",
        "\n",
        "# --- Set Today's Directory ---\n",
        "today_dir = \"Assignments/HW2\"\n",
        "if os.path.exists(today_dir) and os.path.isdir(today_dir):\n",
        "    os.chdir(today_dir)\n",
        "    print(f\"ðŸ“‚ Changed directory to: {os.getcwd()}\")\n",
        "else:\n",
        "    print(f\"âŒ ERROR: Today's directory '{today_dir}' not found relative to {os.getcwd()}.\")\n",
        "    print(f\"ðŸ’¡ Please ensure '{today_dir}' exists in your cloned repository.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgqVsvdbr4Wp",
        "outputId": "5d20d09c-20eb-43b8-fa83-f4a513162783"
      },
      "id": "PgqVsvdbr4Wp",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸŒ Already in /content.\n",
            "âœ… Repo 'STAT-7220-Applied-Experimental-Design' already exists. Changed directory to: /content/STAT-7220-Applied-Experimental-Design\n",
            "ðŸ”— Connected to fork at: https://github.com/Cipher212/STAT-7220-Applied-Experimental-Design.git\n",
            "ðŸ“‚ Changed directory to: /content/STAT-7220-Applied-Experimental-Design/Assignments/HW2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "473cf89b",
      "metadata": {
        "id": "473cf89b"
      },
      "source": [
        "# Homework 2: Randomized Block and Latin Square Designs\n",
        "## Dr. Austin R. Brown\n",
        "### School of Data Science & Analytics\n",
        "### Kennesaw State University\n",
        "\n",
        "**DUE: February 20, 2026**\n",
        "\n",
        "**PART 1 INSTRUCTIONS:** You are an educational researcher interested in comparing different methods for teaching data science to undergraduate students. There are three different methods you are interested in comparing: (1) Direct Instruction (traditional method); (2) Inquiry-Based Learning (teacher facilitates student problem solving); (3) Collaborative Learning (students working in small groups). To compare these methods, you decide to randomly recruit undergraduate data science students to be part of a workshop on hypothesis testing basics. Students will be randomly assigned to one of three workshops, where each workshop employs a different teaching method. At the end of the workshop, students will be given a 50-question quiz where their understanding of hypothesis testing will be assessed. Percentage scores on this quiz serve as the outcome of interest.\n",
        "\n",
        "However, it would be apparent that the prior level of knowledge a student possess about hypothesis testing may serve as a potential confounding variable that you would want to control for. Thus, the Prior Knowledge a given student has about hypothesis testing is categorized into \"High\" and \"Low\". The data from this experiment are contained in the `Data Science Teaching Method.xlsx` file. With these data, your tasks are:\n",
        "\n",
        "**Question 1.** Briefly define the objective of this experiment\n",
        "\n",
        "**Question 2.** Specify the outcome variable\n",
        "\n",
        "**Question 3.** Specify the independent variable and blocking factor. What are some possible lurking variables?\n",
        "\n",
        "**Question 4.** Briefly explain why a randomized block design would be appropriate here. Similarly, explain why a completely randomized design would not be appropriate.\n",
        "\n",
        "**Question 5.** State the null and alternative hypotheses for this experiment.\n",
        "\n",
        "**Question 6.** Perform appropriate exploratory analysis, including summary statistics **and** data visualizations. Do the results of these analyses support the null or alternative hypothesis more strongly?\n",
        "\n",
        "**Question 7.** Build a two-way ANOVA model. Test the assumption of normality using **both** a visual method and a testing method. Do the results of the normality test(s) support the assumption of normality?\n",
        "\n",
        "**Question 8.** Test the assumption of homogeneity of variance using **both** a visual method and a testing method. Do the results of the test(s) support the assumption of homogeneity of variance?\n",
        "\n",
        "**Question 9.** Report the F-statistic and its associated p-value for the treatment effect. Which of our two hypotheses is more strongly supported? Why?\n",
        "\n",
        "**Question 10.** If the data more strongly support the alternative hypothesis, perform Tukey's HSD post-hoc test to determine which levels of the treatment effect are significantly different from each other. If the data more strongly support the null hypothesis, explain why a post-hoc test would not be appropriate.\n",
        "\n",
        "**Question 11.** Write a brief, contextual conclusion summarizing the results of your analyses, including potential limitations and future directions of this experiment.\n",
        "\n",
        "**PART 2 INSTRUCTIONS**: Now suppose a university is evaluating the effectiveness of four different online learning platforms (say A, B, C, and D) on student engagement for students taking an undergraduate data science course in an online synchronous format. One section of the course is offered Monday through Thursday in the Morning, Early Afternoon, Mid-Afternoon, and Evening sections. Student engagement is measured through the total number of logins to the online learning platform for a given course section over the course of the\n",
        "semester. Below is a table describing the study design and factors:\n",
        "\n",
        "\n",
        "| Section \\ Day     | Monday | Tuesday | Wednesday | Thursday |\n",
        "|-------------------|--------|---------|-----------|----------|\n",
        "| **Morning**       | A      | B       | C         | D        |\n",
        "| **Early Afternoon** | B      | C       | D         | A        |\n",
        "| **Mid-Afternoon** | C      | D       | A         | B        |\n",
        "| **Evening**       | D      | A       | B         | C        |\n",
        "\n",
        "\n",
        "Here, our main interest is in comparing engagement across the online learning platforms, but we also want to control for Day of the Week as well as Time of Day, as these could potentially be confounding variables. The data for this experiment are contained in the `Online Learning and Engagement.xlsx` file. With these data, your tasks are:\n",
        "\n",
        "**Question 1.** Briefly define the objective of this experiment\n",
        "\n",
        "**Question 2.** Specify the outcome variable\n",
        "\n",
        "**Question 3.** Specify the independent variable and blocking factors. What are some other possible lurking variables?\n",
        "\n",
        "**Question 4.** Briefly explain why a Latin Square Design would be appropriate here. Similarly, explain why a completely randomized design or randomized block design would not be appropriate.\n",
        "\n",
        "**Question 5.** State the null and alternative hypotheses for this experiment.\n",
        "\n",
        "**Question 6.** Perform appropriate exploratory analysis, including summary statistics **and** data visualizations. Do the results of these analyses support the null or alternative hypothesis more strongly?\n",
        "\n",
        "**Question 7.** Build a three-way ANOVA model. Test the assumption of normality using **both** a visual method and a testing method. Do the results of the normality tests) support the assumption of normality?\n",
        "\n",
        "**Question 8.** Test the assumption of homogeneity of variance using **both** a visual method and a testing method. Do the results of the test(s) support the assumption of homogeneity of variance?\n",
        "\n",
        "**Question 9.** Report the F-statistic and its associated p-value for the treatment effect. Which of our two hypotheses is more strongly supported? Why?\n",
        "\n",
        "**Question 10.** If the data more strongly support the alternative hypothesis, perform Tukey's HSD post-hoc test to determine which levels of the treatment effect are significantly different from each other. If the data more strongly support the null hypothesis, explain why a post-hoc test would not be appropriate.\n",
        "\n",
        "**Question 11.** Write a brief conclusion summarizing the results of your analyses, including potential limitations and future directions of this experiment."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd #pandas\n",
        "import seaborn as sns # sebonr\n",
        "import matplotlib.pyplot as plt #matplotlib\n",
        "\n",
        "#statsmodels\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.formula.api import ols\n",
        "import statsmodels.stats.diagnostic as dg\n",
        "from statsmodels.stats.multicomp import pairwise_tukeyhsd # tukeyHSD library\n",
        "from statsmodels.stats.diagnostic import het_breuschpagan # breusch pagan test\n",
        "\n",
        "#scipy\n",
        "from scipy.stats import shapiro\n",
        "from scipy.stats import levene\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df = pd.read_excel('Data Science Teaching Method.xlsx')\n",
        "print(df.head(10))"
      ],
      "metadata": {
        "id": "-_t2CiR3rHL0"
      },
      "id": "-_t2CiR3rHL0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 1**\n",
        "\n",
        "The purpose of this experiment is to determine the effects of a Student's prior knowledge and the teaching method they are subject to, on the student scores. Also, to differentiate the statistical variance caused by Prior Knowledge and Teaching Method on the Score variable in the dataset."
      ],
      "metadata": {
        "id": "IfNf95fDiJ7F"
      },
      "id": "IfNf95fDiJ7F"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 2**\n",
        "\n",
        "Outcome (Dependent) variable would be \"Score\""
      ],
      "metadata": {
        "id": "iQzBoU6EiLBk"
      },
      "id": "iQzBoU6EiLBk"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 3**\n",
        "\n",
        "The independent variable would be the Teaching_Method. Prior_Knowledge works as blocking factor.\n",
        "\n",
        "For lurking factors that could affect \"Score\";\n",
        "\n",
        "- Average class size\n",
        "- Teacher to Student ratio\n",
        "- Asynchronous vs Online vs In-Person attendance\n",
        "- Difference in Time of Day of the classes for each teaching method\n",
        "- Student motivation\n",
        "- Class resources, software and hardware provided to each class/student\n",
        "- Prior programming fluency, not all Data Scientist students are adept in Python/R beforehand\n",
        "- AI usage policy and availability to advanced models\n",
        "\n"
      ],
      "metadata": {
        "id": "Yc_nraugiPen"
      },
      "id": "Yc_nraugiPen"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 4**\n",
        "\n",
        "RDB is more suitable due to the existence of the Prior_Knowledge variable which causes variance in \"Score\". Randomized Block Design would allow us to split the students into High and Low first before randomising for Teaching_Method. Grouping by Prior_knowledge will increase the F-Statistic for Teaching_Method as well.\n",
        "\n",
        "Using CRD from Homework 1 is possible but the Prior_Knowledge will act as confounder for our reuslts and not allow us to isolate the effect of Prior_Knowledge for Score."
      ],
      "metadata": {
        "id": "dh4SR1YBiRiK"
      },
      "id": "dh4SR1YBiRiK"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 5**\n",
        "\n",
        "The point of this study is comparing the 3 teaching methods. The variable on which these 3 can be compared is the Score variable. Hence, the primary test in this randomized block design experiment would be:\n",
        "\n",
        "H0 = There is no significant difference in mean quiz scores between the three teaching methods. The method of instruction has no effect on student performance\n",
        "\n",
        "\n",
        "HA = At least one teaching method results in a mean quiz score that is statistically different from the others\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qtjkFL6PiULd"
      },
      "id": "qtjkFL6PiULd"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 6**\n",
        "\n",
        "\n",
        "**Analysis**\n",
        "\n",
        "\n",
        "*Score*"
      ],
      "metadata": {
        "id": "EZBkHfbDvE1E"
      },
      "id": "EZBkHfbDvE1E"
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "\n",
        "# Score Variable\n",
        "\n",
        "plt.figure(figsize=(15, 6))\n",
        "\n",
        "# Histogram\n",
        "plt.subplot(1, 3, 1)\n",
        "sns.histplot(df['Score'],color='lightblue',bins=20)\n",
        "plt.title('Histogram of Score')\n",
        "plt.xlabel('Score')\n",
        "\n",
        "#boxplot\n",
        "plt.subplot(1, 3, 2)\n",
        "# The 'y' argument creates a vertical boxplot, 'x' creates horizontal\n",
        "sns.boxplot(y=df['Score'], color='lightgreen')\n",
        "plt.title('Boxplot of Score')\n",
        "plt.ylabel('Score')\n",
        "\n",
        "#qqplot\n",
        "\n",
        "sm.qqplot(df['Score'], line='s')\n",
        "\n",
        "plt.title('QQ Plot of Score')\n",
        "plt.show()\n",
        "\n",
        "summary_table = df['Score'].describe().to_frame().T.round(3)\n",
        "\n",
        "print(summary_table)"
      ],
      "metadata": {
        "id": "enUMfI7pvGVW"
      },
      "id": "enUMfI7pvGVW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Observation*"
      ],
      "metadata": {
        "id": "tw31ciVjMtPT"
      },
      "id": "tw31ciVjMtPT"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The histogram proves that the distribution of data is multimodial, there are peaks which signify clustering of scores around at least 3 points. This strongly suggests that Teaching_Method is a controlling factor for Score. The qqplot shows that it is still approximately normal, however. We have enough sample size and ANOVA will not be affected by the multomodial distribution. The anlaysis supports ALTERNATE (Ha) hypothesis more than Null (H0)\n",
        "\n",
        "\n",
        "The distribution of scores is asymmetric.  There are no significant outliers and there is no skew. Range of scores is approx between 60-100. Data is continuous and numeric.\n",
        "\n",
        "\n",
        "Note: There is one student that managed to score more than a 100. This could be an error but will not omit, will assume it to be a 100 + extra credit"
      ],
      "metadata": {
        "id": "2J6XjkvWMlqP"
      },
      "id": "2J6XjkvWMlqP"
    },
    {
      "cell_type": "code",
      "source": [
        "# Teaching_Method and Prior_Knowledge (Categorical Variables)\n",
        "\n",
        "print(df['Teaching_Method'].value_counts())\n",
        "print(df['Prior_Knowledge'].value_counts())\n",
        "\n",
        "\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "# Teaching Method\n",
        "\n",
        "sns.countplot(x='Teaching_Method', data=df, ax=axes[0])\n",
        "axes[0].set_title('Count of Teaching Method')\n",
        "\n",
        "# label\n",
        "for container in axes[0].containers:\n",
        "    axes[0].bar_label(container)\n",
        "\n",
        "# Prior Knoweldge\n",
        "\n",
        "sns.countplot(x='Prior_Knowledge', data=df, ax=axes[1])\n",
        "axes[1].set_title('Count of Prior Knowledge')\n",
        "\n",
        "# labels\n",
        "for container in axes[1].containers:\n",
        "    axes[1].bar_label(container)\n",
        "\n",
        "\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "balance_check = pd.crosstab(df['Teaching_Method'], df['Prior_Knowledge'])\n",
        "\n",
        "print(balance_check)"
      ],
      "metadata": {
        "id": "R3aX-9aoPj0C"
      },
      "id": "R3aX-9aoPj0C",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Observation*\n",
        "\n",
        "All Teaching_Method group sizes are EQUAL and Low/High Prior_Knowledge students are equally distributed for each group. This is the ideal dataset for an ANOVA test as it is orthogonal data.\n",
        "\n",
        "However this does not do anything to support either Null or Alternate hypothesis."
      ],
      "metadata": {
        "id": "kAq0kxmjRYK8"
      },
      "id": "kAq0kxmjRYK8"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 7**"
      ],
      "metadata": {
        "id": "S_NFWeWTWL7J"
      },
      "id": "S_NFWeWTWL7J"
    },
    {
      "cell_type": "code",
      "source": [
        "model = ols('Score ~ C(Teaching_Method) * C(Prior_Knowledge)', data=df).fit()\n",
        "anova_table = sm.stats.anova_lm(model, typ=2)\n",
        "\n",
        "print(anova_table)\n",
        "residuals = model.resid\n",
        "\n",
        "\n",
        "#qq plot\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(6, 5))\n",
        "sm.qqplot(residuals, line='s', ax=ax)\n",
        "plt.title('Q-Q Plot of residuals')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# shapiro wilkes\n",
        "\n",
        "\n",
        "# H0:  Dataset IS normally distributed\n",
        "# HA: Dataset is not normally distributed\n",
        "\n",
        "stat, p_value = shapiro(residuals)\n",
        "print(f\"Shapiro-Wilk Test Statistic: {stat:.4f}\")\n",
        "print(f\"p-value: {p_value:.4f}\")"
      ],
      "metadata": {
        "id": "j2Rg89EOWUfU"
      },
      "id": "j2Rg89EOWUfU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Interpretation*\n",
        "\n",
        "\n",
        "The QQplot of residuals supports assumption of normality as it follows the line mostly, except at the tails. Shapiro Wilke Test Statistic of 0.9886 with p-value > 0.05 also strongly supports assumption of normality as we FAIL to reject Null hypothesis"
      ],
      "metadata": {
        "id": "-29rDg5ADzeL"
      },
      "id": "-29rDg5ADzeL"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 8**\n",
        "\n",
        "We will be using a Residual vs Fitted scatterplot and the Levene's test to see if we're satsifying the assumption of homogenity of variance for the ANOVA from Q.7\n",
        "\n",
        "For this test assume:\n",
        "\n",
        "H0 = Homogenity of Variance\n",
        "Ha = At least one group variance is significantly different"
      ],
      "metadata": {
        "id": "-Z9GlUN4XHYj"
      },
      "id": "-Z9GlUN4XHYj"
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.stats.diagnostic as dg\n",
        "\n",
        "\n",
        "# 1. STUDENTIZED RESIDUALS VS. FITTED SCATTERPLOT\n",
        "standardized_residuals = model.get_influence().resid_studentized_internal\n",
        "fitted_values = model.fittedvalues\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.scatterplot(x=fitted_values, y=standardized_residuals)\n",
        "plt.axhline(0, color='red', linestyle='-')\n",
        "plt.axhline(3, color='blue', linestyle='--')\n",
        "plt.axhline(-3, color='blue', linestyle='--')\n",
        "plt.title(\"Standardized Residuals vs. Fitted\", fontsize=16)\n",
        "plt.xlabel(\"Fitted\")\n",
        "plt.ylabel(\"Standardized Resid.\")\n",
        "plt.show()\n",
        "\n",
        "# 2. BREUSCH-PAGAN TEST\n",
        "bp_test = dg.het_breuschpagan(model.resid, model.model.exog)\n",
        "labels = ['Lagrange multiplier statistic', 'p-value', 'f-value', 'f p-value']\n",
        "\n",
        "print(\"Breusch-Pagan Test\")\n",
        "for label, value in zip(labels, bp_test):\n",
        "    print(f\"{label}: {value:.4f}\")\n",
        "\n",
        "\n",
        "bp_p_value = bp_test[1]\n",
        "\n",
        "print(\"\\nConclusion:\")\n",
        "if bp_p_value < 0.05:\n",
        "    print(\"Heteroscedasticity detected (reject H0). Constant Variance not assumed.\")\n",
        "else:\n",
        "    print(\"No heteroscedasticity detected (fail to reject H0). Constant Variance assumed.\")"
      ],
      "metadata": {
        "id": "vsXlbuLQXIfP"
      },
      "id": "vsXlbuLQXIfP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Observation*\n",
        "\n",
        "We fail to reject null hypothesis due to p-value > 0.05. For scatterplot, while it is not perfectly symmetric, it does not show any 'funnel' effect which is what is observed when homoscedasticity is violated."
      ],
      "metadata": {
        "id": "UVty7-GRc6DA"
      },
      "id": "UVty7-GRc6DA"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 9**\n",
        "\n",
        "We had following output for Teaching_method on Score in our ANOVA test:\n",
        "\n",
        "F-statistic: 11.49\n",
        "p-value: 0.000070\n",
        "\n",
        "Recalling our null and alternate to be:\n",
        "\n",
        "*H0 = There is no significant difference in mean quiz scores between the three teaching methods. The method of instruction has no effect on student performance*\n",
        "\n",
        "\n",
        "*Ha = At least one teaching method results in a mean quiz score that is statistically different from the others*\n",
        "\n",
        "We can safely reject the null (H0) hypothesis as we have p-value < 0.05. F-Statistic is also large enough to justify that effect from teaching_method on score is not random errors within dataset.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0yUfVzaMiyHf"
      },
      "id": "0yUfVzaMiyHf"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 10**\n",
        "\n"
      ],
      "metadata": {
        "id": "ifiSXY2HkZMA"
      },
      "id": "ifiSXY2HkZMA"
    },
    {
      "cell_type": "code",
      "source": [
        "tukey = pairwise_tukeyhsd(endog=df['Score'],\n",
        "                          groups=df['Teaching_Method'],\n",
        "                          alpha=0.05)\n",
        "\n",
        "print(\"tukey HSD post hoc result\")\n",
        "print(tukey)"
      ],
      "metadata": {
        "id": "hw0Fa-5ProcZ"
      },
      "id": "hw0Fa-5ProcZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Observation*\n",
        "\n",
        "After running TukeyHSD, we can see that Direct teaching method is the only one to have a statistically significant difference in mean from another method, when compared to the collaborative method. However, in Direct vs Inquiry, the p-value > 0.05 means we cannot declare Direct a winner against all other methods."
      ],
      "metadata": {
        "id": "SQ3XUWwQuK22"
      },
      "id": "SQ3XUWwQuK22"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 11**\n",
        "\n",
        "Primary goal of experiment was to find if teaching methods have any impact on student scores when controlling for Prior_Knowledge variable.\n",
        "\n",
        "In ANOVA, we found high significance for statistical effect of teaching_method on score. (p=0.00007), residuals were also confirmed to be normally distributed (SW p=0.8498) and variances were equal across all groups as per BP-test (p=~0.7228).\n",
        "\n",
        "Once we rejected null hypothesis, we performed TukeyHSD which showed that \"Direct\" teaching method was statistically greater than Collberative instruction method by 9.6 points with p-value (0.0003). However , Direct instruction was not statistically greater than Inquiry method (p=0.1168). It may be possible that Direct and Inquiry methods are comparable on performance.\n",
        "\n",
        "\n",
        "There are limitations in this experiment, a larger sample size could have helped in the TukeyHSD comparison between Direct and Inquiry method. The experiment itself was focused on one single quizz and not the entire class cirriculum.\n",
        "\n",
        "For future experimentation, it would be useful to measure statistical significance of teaching methods over a semester length to see if certain methods improve over time. For example, in collaberative if the groups are new, they may perform poorly initially and get better as they work together. Also, filtering students by the timing of their classes (Morning, Afternoon, Evening, Night)\n",
        "\n"
      ],
      "metadata": {
        "id": "t90ViX7TvBkr"
      },
      "id": "t90ViX7TvBkr"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PART 2**\n",
        "\n",
        "\n",
        "**Question 1**\n",
        "\n",
        "\n",
        "Objective would be to compare variable \"engagement\" for 4 different online learning platforms (A,B,C,D) while controlling for \"Day\" and \"Section\" (Time of the Day)\n",
        "\n",
        "**Question 2**\n",
        "\n",
        "Outcome variable would be \"Engagement\"\n",
        "\n",
        "**Question 3**\n",
        "\n",
        "IV: \"Platform\" - Categorical\n",
        "DV: \"Engagement\" - Numerical\n",
        "\n",
        "Blocking Factors:\n",
        "Day of the Week (Day)\n",
        "Time of Day (Section)\n",
        "\n",
        "Lurking Variables:\n",
        "\n",
        "1. Student Prior Knowledge\n",
        "\n",
        "2. Internet connection and facilities - What device is each student using, do they have a good connection, right hardware to run programs required by class\n",
        "\n",
        "3. Instructor teaching proficiency, method - Some professors skills do not translate over for teaching online classes\n",
        "\n",
        "4. Course difficulty/content level by week - Some weeks are more hectic than others in a class\n",
        "\n",
        "5. Ease of installation and operation of the online platform itself -\n",
        "Is it a simple click .exe, or does it require connection to the university VPS first or a Github?\n",
        "\n",
        "**Question 4**\n",
        "\n",
        "Latin square design makes sense here as it can counter for two blocking/confounding factors, which is what this experiment has with the Day of Week and Time of Day variables. Using Randomised block from Part 1 is also inappropriate as it usually accounts for one blocking factor.\n",
        "\n",
        "\n",
        "**Question 5**\n",
        "\n",
        "H0 = There is no significant difference in the mean student engagement time across all 4 Online Learning Platforms\n",
        "\n",
        "Ha = At least one Online Learning Platform has a statistically signficant difference in mean student engagement time.\n",
        "\n",
        "\n",
        "**Question 6**"
      ],
      "metadata": {
        "id": "Trc5ufAXzxFY"
      },
      "id": "Trc5ufAXzxFY"
    },
    {
      "cell_type": "code",
      "source": [
        "# EDA\n",
        "\n",
        "\n",
        "sns.set_style(\"whitegrid\")\n",
        "\n",
        "\n",
        "#file import\n",
        "df_online = pd.read_excel(\"Online Learning and Engagement.xlsx\")\n",
        "\n",
        "overall_stats = df_online.groupby('Platform')['Engagement'].describe()\n",
        "print(\"Overview\")\n",
        "print(overall_stats)\n",
        "\n",
        "#boxplot\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.title(\"EDA\\n Boxplot\")\n",
        "sns.boxplot(x='Platform', y='Engagement', data=df_online, palette='Set2', order=['A', 'B', 'C', 'D'])\n",
        "\n",
        "\n",
        "# blockin gfactors boxplot\n",
        "\n",
        "plt.figure(figsize=(14, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.boxplot(x=\"Day\", y=\"Engagement\", data=df_online, palette=\"Pastel1\", order=['Monday', 'Tuesday', 'Wednesday', 'Thursday'])\n",
        "plt.title(\"Engagement by Day\")\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.boxplot(x=\"Section\", y=\"Engagement\", data=df_online, palette=\"Pastel2\",\n",
        "            order=['Morning', 'Early Afternoon', 'Mid Afternoon', 'Evening'])\n",
        "plt.title(\"Engagement by Section\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mF_0klxFMscj"
      },
      "id": "mF_0klxFMscj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Observation*\n",
        "\n",
        "Our EDA showed that A platform has highest average engagement (~ 1409 logins) while platform B and C (~ 1333 logins) have lower mean. The amount of separate and lack of overlap strongly supports the Alternate (Ha) hypothesis over Null.\n",
        "\n",
        "The exploratory analysis also shows significant variance in mean engagement across different Days and time sections. This justifies using a Latin Square Design.\n",
        "\n"
      ],
      "metadata": {
        "id": "DodCHf4CI9W0"
      },
      "id": "DodCHf4CI9W0"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 7**"
      ],
      "metadata": {
        "id": "7D5kywrFNIMe"
      },
      "id": "7D5kywrFNIMe"
    },
    {
      "cell_type": "code",
      "source": [
        "# build model\n",
        "model = ols(\"Engagement ~ C(Day) + C(Section) + C(Platform)\", data=df_online).fit()\n",
        "\n",
        "# 3 way ANOVA\n",
        "model_table = sm.stats.anova_lm(model, typ=1)\n",
        "print(model_table)\n",
        "\n",
        "# using studentized residuasl\n",
        "studentized_residuals = model.get_influence().resid_studentized_internal\n",
        "\n",
        "# qqplot\n",
        "\n",
        "sm.qqplot(studentized_residuals, line='s')\n",
        "plt.title(\"Q-Q Plot of Studentized Residuals\", fontsize=14)\n",
        "plt.show()\n",
        "\n",
        "# shapiro wilke\n",
        "\n",
        "sw_stat, sw_p = shapiro(studentized_residuals)\n",
        "\n",
        "print(f\"Shapiro-Wilk Statistic: {sw_stat:.4f}\")\n",
        "print(f\"Shapiro-Wilk p-value: {sw_p:.4f}\")"
      ],
      "metadata": {
        "id": "ITIn4v15NJd5"
      },
      "id": "ITIn4v15NJd5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Observation*\n",
        "\n",
        "Assumption normality is strongly suported by both the visual and statistical output. QQ plot of studentised residual shows plot points following 45 degree ref line with no major outliers.  \n",
        "\n",
        "Shapiro Wilk test gave p-value > 0.05, hence the studentised residuals of this model meet assumption of normality.\n",
        "\n",
        "ANOVA table surprisingly shows that both Day and Section are not statsitically significant for affecting Engagement, but Teaching Method (A,B,C,D) has statistically significant impact on student engagement (p-value < 0.05) with F score of ~7.\n",
        "\n"
      ],
      "metadata": {
        "id": "_48oLDG_S0xS"
      },
      "id": "_48oLDG_S0xS"
    },
    {
      "cell_type": "markdown",
      "source": [
        "** Question 8**\n"
      ],
      "metadata": {
        "id": "p9fYNhjBWgaj"
      },
      "id": "p9fYNhjBWgaj"
    },
    {
      "cell_type": "code",
      "source": [
        "# visual - studentised fitted vs residua lscatterplot\n",
        "\n",
        "fitted_values = model.fittedvalues\n",
        "studentized_residuals = model.get_influence().resid_studentized_internal\n",
        "\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.scatterplot(x=fitted_values, y=studentized_residuals)\n",
        "plt.axhline(0, color='red', linestyle='-')\n",
        "plt.title(\" Residuals vs. Fitted \", fontsize=14)\n",
        "plt.xlabel(\"Fitted \")\n",
        "plt.ylabel(\" Residuals\")\n",
        "plt.show()\n",
        "\n",
        "# statistical - Breusch pagan Test\n",
        "\n",
        "bp_test = het_breuschpagan(model.resid, model.model.exog)\n",
        "labels = ['LM Statistic', 'LM-Test p-value', 'F-Statistic', 'F-Test p-value']\n",
        "bp_results = dict(zip(labels, bp_test))\n",
        "\n",
        "print(pd.Series(bp_results).round(3))"
      ],
      "metadata": {
        "id": "KydELH63Y4yR"
      },
      "id": "KydELH63Y4yR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Observation*\n",
        "\n",
        "\n",
        "student. Residuals vs Fitted plot shows a random scattering of point around zero line. No funneling or pattern is present, which suggests homosecedasticity\n",
        "\n",
        "Our bruesch pagan test with p-value > 0.05 also suggests constant variance in the model."
      ],
      "metadata": {
        "id": "2_ZCffj_aXW_"
      },
      "id": "2_ZCffj_aXW_"
    },
    {
      "cell_type": "markdown",
      "source": [
        "** Question 9**\n",
        "\n",
        "The $F$-statistic for the treatment effect (Platform) is 7.61, with an associated $p$-value of 0.0181.\n",
        "\n",
        "F-Statistic for Platform was 7.61, with p-value 0.0181 (below Alpha). These stats support Ha hypothesis more than H0.\n"
      ],
      "metadata": {
        "id": "98-XrUwGbVVs"
      },
      "id": "98-XrUwGbVVs"
    },
    {
      "cell_type": "markdown",
      "source": [
        "** Question 10**\n",
        "\n",
        "Performing Tukey HSD test after rejecting Null hypothesis:"
      ],
      "metadata": {
        "id": "HiFi5REpbm5W"
      },
      "id": "HiFi5REpbm5W"
    },
    {
      "cell_type": "code",
      "source": [
        "tukey_results = pairwise_tukeyhsd(endog=df_online['Engagement'],\n",
        "                                 groups=df_online['Platform'],\n",
        "                                 alpha=0.05)\n",
        "\n",
        "print(tukey_results)"
      ],
      "metadata": {
        "id": "ddoyUmnhcEqr"
      },
      "id": "ddoyUmnhcEqr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Observation*\n",
        "\n",
        "\n",
        "TukeyHSD output shows that Platform A, as seen in initial boxplot during EDA outperformed Platform B and C with statistical significance. However, no other pairwise comparison has sttisticial significance.\n",
        "\n",
        "Similar to Part 1 of this homework, we can see that statistically one event/item in dataset has a signficiantly higher average value, but low sample size prevents fully confirming it."
      ],
      "metadata": {
        "id": "nYukg_dqdG1c"
      },
      "id": "nYukg_dqdG1c"
    },
    {
      "cell_type": "markdown",
      "source": [
        "** Question 11**\n",
        "\n",
        "\n",
        "The 3 way ANOVA showed that learning platform had a statistically significant impact on Engagement with F-value 7.61 and p-value < 0.05. While the EDA showed variance for Days and Section, which was the basis of doing the Latin Square Design (more than 1 confounder variable), the test results showed that they were not actually statistically signficant.  EDA also suggested Platform A would be the winner\n",
        "\n",
        "TukeyHSD backed this up showing 2 clear instance of statistical superiority of Platform A over B and C.\n",
        "\n",
        "However this experiment was limited by low sample size which prevented model from confirming significance of Platform A's higher engagement average. Using a different experiment method to increase statistical power would help to resolve pairwise comparisons."
      ],
      "metadata": {
        "id": "WBuSaxXlel98"
      },
      "id": "WBuSaxXlel98"
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}